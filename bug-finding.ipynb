{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: annotated-types==0.7.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 1)) (0.7.0)\n",
      "Requirement already satisfied: appnope==0.1.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 2)) (0.1.4)\n",
      "Requirement already satisfied: asttokens==2.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 3)) (2.4.1)\n",
      "Requirement already satisfied: blis==1.0.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 4)) (1.0.1)\n",
      "Requirement already satisfied: cachetools==5.5.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 5)) (5.5.0)\n",
      "Requirement already satisfied: catalogue==2.0.10 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 6)) (2.0.10)\n",
      "Requirement already satisfied: certifi==2024.8.30 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 7)) (2024.8.30)\n",
      "Requirement already satisfied: charset-normalizer==3.4.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 8)) (3.4.0)\n",
      "Requirement already satisfied: click==8.1.7 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 9)) (8.1.7)\n",
      "Requirement already satisfied: cloudpathlib==0.20.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 10)) (0.20.0)\n",
      "Requirement already satisfied: comm==0.2.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 11)) (0.2.2)\n",
      "Requirement already satisfied: confection==0.1.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 12)) (0.1.5)\n",
      "Requirement already satisfied: cymem==2.0.8 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 13)) (2.0.8)\n",
      "Requirement already satisfied: debugpy==1.8.7 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 14)) (1.8.7)\n",
      "Requirement already satisfied: decorator==5.1.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 15)) (5.1.1)\n",
      "Requirement already satisfied: executing==2.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 16)) (2.1.0)\n",
      "Requirement already satisfied: frozendict==2.4.6 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 17)) (2.4.6)\n",
      "Requirement already satisfied: future==1.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 18)) (1.0.0)\n",
      "Requirement already satisfied: html5lib-modern==1.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 19)) (1.2)\n",
      "Requirement already satisfied: idna==3.10 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 20)) (3.10)\n",
      "Requirement already satisfied: ipykernel==6.29.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 21)) (6.29.5)\n",
      "Requirement already satisfied: ipython==8.28.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 22)) (8.28.0)\n",
      "Requirement already satisfied: jedi==0.19.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 23)) (0.19.1)\n",
      "Requirement already satisfied: Jinja2==3.1.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 24)) (3.1.4)\n",
      "Requirement already satisfied: jupyter_client==8.6.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 25)) (8.6.3)\n",
      "Requirement already satisfied: jupyter_core==5.7.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 26)) (5.7.2)\n",
      "Requirement already satisfied: langcodes==3.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 27)) (3.4.1)\n",
      "Requirement already satisfied: language_data==1.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 28)) (1.2.0)\n",
      "Requirement already satisfied: LinkHeader==0.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 29)) (0.4.3)\n",
      "Requirement already satisfied: lxml==5.3.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 30)) (5.3.0)\n",
      "Requirement already satisfied: marisa-trie==1.2.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 31)) (1.2.1)\n",
      "Requirement already satisfied: markdown-it-py==3.0.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 32)) (3.0.0)\n",
      "Requirement already satisfied: MarkupSafe==3.0.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 33)) (3.0.2)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.7 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 34)) (0.1.7)\n",
      "Requirement already satisfied: mdurl==0.1.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 35)) (0.1.2)\n",
      "Requirement already satisfied: murmurhash==1.0.10 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 36)) (1.0.10)\n",
      "Requirement already satisfied: MyCapytain==3.0.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 37)) (3.0.2)\n",
      "Requirement already satisfied: nest-asyncio==1.6.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 38)) (1.6.0)\n",
      "Requirement already satisfied: numpy==2.0.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 39)) (2.0.2)\n",
      "Requirement already satisfied: packaging==24.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 40)) (24.1)\n",
      "Requirement already satisfied: pandas==2.2.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 41)) (2.2.3)\n",
      "Requirement already satisfied: parso==0.8.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 42)) (0.8.4)\n",
      "Requirement already satisfied: pexpect==4.9.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 43)) (4.9.0)\n",
      "Requirement already satisfied: platformdirs==4.3.6 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 44)) (4.3.6)\n",
      "Requirement already satisfied: preshed==3.0.9 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 45)) (3.0.9)\n",
      "Requirement already satisfied: prompt_toolkit==3.0.48 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 46)) (3.0.48)\n",
      "Requirement already satisfied: psutil==6.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 47)) (6.1.0)\n",
      "Requirement already satisfied: ptyprocess==0.7.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 48)) (0.7.0)\n",
      "Requirement already satisfied: pure_eval==0.2.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 49)) (0.2.3)\n",
      "Requirement already satisfied: pydantic==2.9.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 50)) (2.9.2)\n",
      "Requirement already satisfied: pydantic_core==2.23.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 51)) (2.23.4)\n",
      "Requirement already satisfied: Pygments==2.18.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 52)) (2.18.0)\n",
      "Requirement already satisfied: PyLD==2.0.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 53)) (2.0.4)\n",
      "Requirement already satisfied: pyparsing==3.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 54)) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil==2.9.0.post0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 55)) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz==2024.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 56)) (2024.2)\n",
      "Requirement already satisfied: pyzmq==26.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 57)) (26.2.0)\n",
      "Requirement already satisfied: rdflib==7.1.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 58)) (7.1.0)\n",
      "Requirement already satisfied: rdflib-jsonld==0.6.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 59)) (0.6.2)\n",
      "Requirement already satisfied: requests==2.32.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 60)) (2.32.3)\n",
      "Requirement already satisfied: rich==13.9.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 61)) (13.9.2)\n",
      "Requirement already satisfied: setuptools==75.2.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 62)) (75.2.0)\n",
      "Requirement already satisfied: shellingham==1.5.4 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 63)) (1.5.4)\n",
      "Requirement already satisfied: six==1.16.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 64)) (1.16.0)\n",
      "Requirement already satisfied: smart-open==7.0.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 65)) (7.0.5)\n",
      "Requirement already satisfied: spacy==3.8.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 66)) (3.8.2)\n",
      "Requirement already satisfied: spacy-legacy==3.0.12 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 67)) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers==1.0.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 68)) (1.0.5)\n",
      "Requirement already satisfied: srsly==2.4.8 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 69)) (2.4.8)\n",
      "Requirement already satisfied: stack-data==0.6.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 70)) (0.6.3)\n",
      "Requirement already satisfied: thinc==8.3.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 71)) (8.3.2)\n",
      "Requirement already satisfied: tornado==6.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 72)) (6.4.1)\n",
      "Requirement already satisfied: tqdm==4.66.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 73)) (4.66.5)\n",
      "Requirement already satisfied: traitlets==5.14.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 74)) (5.14.3)\n",
      "Requirement already satisfied: typer==0.12.5 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 75)) (0.12.5)\n",
      "Requirement already satisfied: typing==3.7.4.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 76)) (3.7.4.3)\n",
      "Requirement already satisfied: typing_extensions==4.12.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 77)) (4.12.2)\n",
      "Requirement already satisfied: tzdata==2024.2 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 78)) (2024.2)\n",
      "Requirement already satisfied: urllib3==2.2.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 79)) (2.2.3)\n",
      "Requirement already satisfied: wasabi==1.1.3 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 80)) (1.1.3)\n",
      "Requirement already satisfied: wcwidth==0.2.13 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 81)) (0.2.13)\n",
      "Requirement already satisfied: weasel==0.4.1 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 82)) (0.4.1)\n",
      "Requirement already satisfied: wrapt==1.16.0 in /home/codespace/.local/lib/python3.12/site-packages (from -r requirements.txt (line 83)) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "f = Path(f\"./tlg0525.tlg001.perseus-eng2.pickle\")\n",
    "\n",
    "def tokenize(df: pd.DataFrame):\n",
    "    model = \"en_core_web_sm\"\n",
    "\n",
    "    nlp = spacy.load(model, disable=[\"ner\"])\n",
    "\n",
    "    df[\"tokens\"] = df[\"unannotated_strings\"].apply(nlp.tokenizer)\n",
    "\n",
    "    raw_texts = [t for t in df[\"unannotated_strings\"]]\n",
    "    annotated_texts = nlp.pipe(raw_texts, batch_size=100)\n",
    "\n",
    "    df[\"nlp_docs\"] = list(annotated_texts)\n",
    "\n",
    "    return df\n",
    "\n",
    "df = tokenize(pd.read_pickle(f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug 1\n",
    "\n",
    "Why is the function `expected_frequency_of_collocation(df: pd.DataFrame, node: str, collocate: str, window_size: int = 1)` returning `0.0` no matter what we pass to it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def expected_frequency_of_collocation(df: pd.DataFrame, node: str, collocate: str, window_size: int = 1):\n",
    "    \"\"\"\n",
    "    `node` and `collocate` should be the string representations\n",
    "    of the associated lemmata\n",
    "    \"\"\"\n",
    "\n",
    "    lemmata = [t for t in df['nlp_docs'].explode()]\n",
    "    counter = Counter(lemmata)\n",
    "    node_count = counter[node]\n",
    "    collocate_count = counter[collocate]\n",
    "\n",
    "    return (node_count * collocate_count * window_size) / len(lemmata)\n",
    "\n",
    "expected_freq_the_mainlaind = expected_frequency_of_collocation(df, \"mainland\", \"the\")\n",
    "\n",
    "expected_freq_the_mainlaind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug 1 analysis and response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe this is because lemmata is not properly defined. That is, I think the code should be: \n",
    "lemmata = [t.lemma_ for t in df['nlp_docs].explode() \n",
    "\n",
    "I also changed the / len (lemmata) to / len(df['tokens].explode()), since I believe we need to divide by the number of tokens--not the number of lemmata--in the corpus in order to get the expected collocation frequency. \n",
    "\n",
    "This got me a result of 3.284, although I am not confident this is correct either. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.2848751741271176"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def expected_frequency_of_collocation(df: pd.DataFrame, node: str, collocate: str, window_size: int = 1):\n",
    "    \"\"\"\n",
    "    `node` and `collocate` should be the string representations\n",
    "    of the associated lemmata\n",
    "    \"\"\"\n",
    "\n",
    "    lemmata = [t.lemma_ for t in df['nlp_docs'].explode()] ## changed this line\n",
    "    counter = Counter(lemmata)\n",
    "    node_count = counter[node]\n",
    "    collocate_count = counter[collocate]\n",
    "\n",
    "    return (node_count * collocate_count * window_size) / len(df['tokens'].explode()) # I changed this \n",
    "\n",
    "\n",
    "expected_freq_the_mainland = expected_frequency_of_collocation(df, \"mainland\", \"the\")\n",
    "\n",
    "expected_freq_the_mainland\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26932"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmata = [t.lemma_ for t in df['nlp_docs'].explode()] ## changed this line\n",
    "counter = Counter(lemmata)\n",
    "node_count = counter[node]\n",
    "collocate_count = counter[collocate]\n",
    "\n",
    "counter['the']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug 2\n",
    "\n",
    "Why does the code below not give us the number of occurrences of the token \"the\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "        ..\n",
       "3165   NaN\n",
       "3166   NaN\n",
       "3167   NaN\n",
       "3168   NaN\n",
       "3169   NaN\n",
       "Name: tokens, Length: 3170, dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observed_freq_the = df['tokens'].str.find('the')\n",
    "\n",
    "observed_freq_the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug 2 analysis and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26932"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmata = [t.lemma_ for t in df['nlp_docs'].explode()] \n",
    "counter = Counter(lemmata)\n",
    "observed_freq_the = counter['the']\n",
    "\n",
    "observed_freq_the\n",
    "## 26,932 occurences of 'the'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original code didn't work because .find() is not a count function. I don't understand the approach original code was taking, so my \"fix\" may not be what you are looking for. But instead of tweaking it, I tried a different method to get the frequency using the Counter function to count the occurences of the lemma 'the.' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug 3\n",
    "\n",
    "How is `o11` greater than `r1`, and why is our `o12` negative?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1: 38, r2: 311516, c1: 26932, c2: 284622, o11: 63, o12: -25, o21: 26869\n"
     ]
    }
   ],
   "source": [
    "node = \"mainland\"\n",
    "collocate = \"the\"\n",
    "\n",
    "def count_ngram_collocations(x, w1, w2, l_size: int = 1, r_size: int = 1):\n",
    "    lemmata = [t.lemma_ for t in x]\n",
    "\n",
    "    # the right-hand side of a slice in Python is exclusive, so we add 1 to make sure\n",
    "    # we're actually getting one element to the right\n",
    "\n",
    "    chunked_lemmata = [lemmata[i - l_size:i + r_size + 1] for i in range(0, len(lemmata))]\n",
    "    \n",
    "    cooccurrences = [1 for l in chunked_lemmata if w1 in l and w2 in l]\n",
    "\n",
    "    return sum(cooccurrences)\n",
    "\n",
    "r1 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ == node])\n",
    "r2 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ != node])\n",
    "c1 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ == collocate])\n",
    "c2 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ != collocate])\n",
    "\n",
    "o11 = (df[\"nlp_docs\"].apply(count_ngram_collocations, args=(node, collocate))).sum()\n",
    "o12 = r1 - o11\n",
    "o21 = c1 - o11\n",
    "\n",
    "print(f\"r1: {r1}, r2: {r2}, c1: {c1}, c2: {c2}, o11: {o11}, o12: {o12}, o21: {o21}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug 3 analysis and response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r1: 38, r2: 311516, c1: 26932, c2: 284622, o11: 23, o12: 15, o21: 26909\n"
     ]
    }
   ],
   "source": [
    "def count_ngram_collocations(x, w1, w2, l_size: int = 1, r_size: int = 1):\n",
    "    lemmata = [t.lemma_ for t in x]\n",
    "\n",
    "    indexes = [i for i, lemma in enumerate(lemmata) if lemma == w1]\n",
    "\n",
    "    cooccurrences = 0\n",
    "\n",
    "    for i in indexes:\n",
    "        left = max(i - l_size, 0)\n",
    "        right = min(i + r_size + 1, len(lemmata))\n",
    "        window = lemmata[left:right]\n",
    "\n",
    "        if w2 in window:\n",
    "            cooccurrences += 1\n",
    "\n",
    "    return cooccurrences\n",
    "\n",
    "def count_ngram_non_collocations(x, w1, w2, l_size: int = 1, r_size: int = 1):\n",
    "    lemmata = [t.lemma_ for t in x]\n",
    "\n",
    "    indexes = [i for i, lemma in enumerate(lemmata) if lemma == w1]\n",
    "\n",
    "    non_cooccurrences = 0\n",
    "\n",
    "    for i in indexes:\n",
    "        left = max(i - l_size, 0)\n",
    "        right = min(i + r_size + 1, len(lemmata))\n",
    "        window = lemmata[left:right]\n",
    "\n",
    "        if w2 not in window:\n",
    "            non_cooccurrences += 1\n",
    "\n",
    "    return non_cooccurrences\n",
    "\n",
    "r1 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ == node])\n",
    "r2 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ != node])\n",
    "c1 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ == collocate])\n",
    "c2 = len([t for t in df[\"nlp_docs\"].explode() if t.lemma_ != collocate])\n",
    "\n",
    "o11 = df[\"nlp_docs\"].apply(count_ngram_collocations, args=(node, collocate)).sum()\n",
    "o12 = df[\"nlp_docs\"].apply(count_ngram_non_collocations, args=(node, collocate)).sum()\n",
    "# o12 = r1 - o11\n",
    "o21 = c1 - o11\n",
    "\n",
    "print(f\"r1: {r1}, r2: {r2}, c1: {c1}, c2: {c2}, o11: {o11}, o12: {o12}, o21: {o21}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this last question, I have to admit that I was completely lost. After many countless attempts to fix the code by trial and error, I referenced the updated code in the week_04_inclass.ipynb, from which I copied and pasted the code above. (I hope this was allowed; I assumed this was \"open book\" like the other quizzes). My coding skills are still very, very basic, and I'm not able to produce or fully understand such complex codes yet. I thought it was better to use the class notebook and try to understand why it works rather than just give up and leave the question blank. \n",
    "\n",
    "I had a feeling that sum(cooccurences) was incorrect and was part of the problem because it was adding frequencies together instead of counting the collocations (how o11 was higher than r1 and the o12 was negative), but I wouldn't have been able to come up with creating an index to \"enumerate\" the cooccurrences on my own. And because I was so hyper-focused on trying to make small changes to the already existing code, it didn't even cross my mind that, since there was one to count the collocations, there needed to be a function to count the non-collocations as well.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
